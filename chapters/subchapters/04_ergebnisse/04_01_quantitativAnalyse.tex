\section{Quantitative Analyse}
\label{sec:quantitativeAnalyse}

Zur Einordnung des untersuchten Forschungsfeldes wurden zunächst grundlegende Merkmale der insgesamt 18 Studien analysiert. 
Abbildung \ref{fig:04_01_quantitativeAnalyse} a) zeigt die jährliche Verteilung der Publikationen sowie die Zuordnung zu verschiedenen Publikationstypen. 
Zwischen 2021 und 2023 erscheinen nur wenige Arbeiten (insgesamt drei), während ab 2024 ein deutlicher Anstieg sichtbar wird. 
Im Jahr 2024 wurden sieben und 2025 wurden acht Publikationen identifiziert, überwiegend Journalartikel, ergänzt durch jeweils ein Konferenzbeitrag, ArXiv-Paper und Whitepaper. 
Dies weist auf ein zunehmendes wissenschaftliches Interesse am Einsatz von KI in Cloud-Native- und Platform-Engineering-Kontexten hin.
Der zeitliche Anstieg der Publikationen fällt mit den jüngsten Fortschritten im Bereich generativer KI zusammen \cite{luComputingEraLarge2024a}.

Ergänzend dazu zeigt eine Word Cloud (Abbildung \ref{fig:04_01_quantitativeAnalyse} b) die am häufigsten vorkommenden Keywords aus allen Publikationen. 
Die Visualisierung bietet einen schnellen Überblick über zentrale thematische Schwerpunkte der Literatur.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_01_quantitativ/04_01_quantitativeAnalyse.png}
    \caption{Jährliche und thematische Verteilung der DevOps AI-Forschung}
    \label{fig:04_01_quantitativeAnalyse}
\end{figure}

\subsection{Anwendungsbereiche der KI im Platform Engineering}
\label{subsec:anwendungsbereiche}
Im ersten Schritt der quantitativen Analyse wurden die insgesamt 18 identifizierten Studien hinsichtlich ihrer Hauptanwendungsbereiche untersucht. 
Dazu wurden die ausgewählten Bereiche in vier Kategorien unterteilt: 
Optimierung von CI/CD-Pipelines, Ressourcen- und Workload-Optimierung, Sicherheits- und Bedrohungserkennung sowie Betrieb und Orchestrierung der Plattform (GenOps).

Die Auswertung zeigt, dass Ressourcen- und Workload-Optimierung mit sieben Publikationen am häufigsten als dominanter Use Case auftritt.
Maßnahmen in diesem Bereich haben häufig einen direkten, messbaren Einfluss auf Kosten und Performance, etwa durch eine bessere Ressourcenauslastung oder stabilere Laufzeiten \cite{karthikputhrayaRoleCloudNativeArchitectures2025}.
An zweiter Stelle folgt der Bereich Betrieb und Orchestrierung mit fünf Publikationen.
Dies deutet darauf hin, dass KI-Ansätze besonders im laufenden Betrieb relevant sind, etwa zur Unterstützung von Monitoring oder der automatisierten Steuerung von Plattformkomponenten \cite{reddygopireddyIntegratingAIDevOps2022}.
Die Optimierung von CI/CD-Pipelines und Sicherheits- und Bedrohungserkennung sind mit jeweils drei Publikationen vertreten.
Beide Anwendungsfelder werden in vielen Arbeiten aufgegriffen, stehen jedoch seltener im Fokus der jeweiligen Studie.
Die Optimierung der CI/CD-Pipeline wird oft als Teilaspekt in ein größeres Gesamtbild der Infrastruktur-Transformation behandelt \cite{supritpattanayakIntegratingAIDevOps2024}.

Abbildung \ref{fig:04_01_01_useCases} zeigt diese Verteilung.
Zu beachten ist, dass viele Studien mehr als einen Bereich ansprechen.
In der Praxis überschneiden sich die Anwendungsbereiche häufig, da KI-Lösungen oft mehrere Aufgaben gleichzeitig unterstützen.
Für die Vergleichbarkeit wurde jedoch jeweils der dominante Use Case pro Publikation ausgewählt. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_01_quantitativ/04_01_01_useCases.png}
    \caption{Verteilung der Anwendungsbereiche}
    \label{fig:04_01_01_useCases}
\end{figure}


\subsection{Herausforderungen der KI-Integration im Platform Engineering}
\label{subsec:herausforderungen}
Im nächsten Schritt wurden die in den Publikationen beschriebenen Herausforderungen analysiert, die beim Einsatz von KI im Platform Engineering auftreten. 
Die analysierten Paper wurden fünf Kategorien zugeordnet. 
Die prozentuale Verteilung ist in Abbildung \ref{fig:04_01_02_herausforderungen} dargestellt.

Die Auswertung zeigt, dass Ressourcenverbrauch und Kosten mit 94 \% (17/18) am häufigsten als Herausforderung genannt werden. 
Ebenfalls häufig werden Skalierbarkeit, Latenz und Monitoring mit 83 \% (15/18) sowie KI-Governance, Datenschutz und Compliance mit 83 \% (15/18) adressiert.
Integrationskomplexität und Abhängigkeiten werden in 78 \% (15/18) der Studien thematisiert.
Die fünfte Kategorie, Datenqualität, Datenverfügbarkeit und Heterogenität, wird in 72 \% (13/18) der Arbeiten als Herausforderung genannt.

Diese Ergebnisse deuten auf ein Spannungsfeld hin: KI wird zwar eingesetzt, um Plattformen effizienter und kostengünstiger zu betreiben, erzeugt jedoch durch Training, Inferenz und zusätzliche Observability- und Datenpipelines oft selbst signifikante Ressourcen- und Betriebskosten \cite{zaaloukCLOUDNATIVEARTIFICIAL}.
Die hohe Nennung von KI-Governance, Datenschutz und Compliance legt zudem nahe, dass der produktive KI-Einsatz in Plattformen häufig weniger an der reinen technischen Machbarkeit scheitert, sondern stark durch Anforderungen an Datenzugriff, Nachvollziehbarkeit und Regelkonformität begrenzt wird \cite{tamanampudiAIEnhancedContinuousIntegration}.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_01_quantitativ/04_01_02_herausforderungen.png}
    \caption{Relative Häufigkeit der Herausforderungen}
    \label{fig:04_01_02_herausforderungen}
\end{figure}


\subsection{Formen des maschinellen Lernens}
\label{subsec:formenDesMaschinellenLernens}
Ein weiterer Bestandteil der quantitativen Analyse umfasst die in den Publikationen verwendeten Formen bzw. Lernparadigmen des maschinellen Lernens. 
Dabei wurde unterschieden zwischen (1) explizit benannt, (2) implizit anhand der beschriebenen Methode ableitbar und (3) nur kurz erwähnt ohne weitere methodische Ausführung.

Die Auswertung zeigt, dass Supervised Learning in den meisten Arbeiten eine zentrale Rolle spielt. 
Es wird in vier Publikationen ausdrücklich beschrieben, elfmal implizit erkennbar und in zwei kurz erwähnt. 
Reinforcement Learning wird insgesamt siebenmal explizit genannt und in vier weiteren Arbeiten erwähnt. 
Unsupervised Learning tritt mit drei expliziten und sieben impliziten Nennungen seltener auf, ist jedoch ebenfalls präsent.


Die Verteilung ist in der folgenden Abbildung \ref{fig:04_01_03_lernparadigmen} dargestellt.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_01_quantitativ/04_01_03_lernparadigmen.png}
    \caption{Formen des maschinellen Lernens}
    \label{fig:04_01_03_lernparadigmen}
\end{figure}

Auffällig ist die deutliche Differenz zwischen explizit und implizit erkennbaren Anwendungen, insbesondere bei Supervised und Unsupervised Learning. 
Dies zeigt, dass viele Publikationen die entsprechenden Paradigmen beschreiben, ohne die zugrunde liegende Lernform ausdrücklich zu benennen.
Ein Erklärungsansatz für die Dominanz von SL ist, dass in Plattformumgebungen häufig gut messbare Zielgrößen und bereits beschriftete Verlaufsdaten vorliegen (z.B. Störungsmeldungen, Support-Tickets oder Metriken mit bekanntem Ergebnis), wodurch sich SL-Ansätze besonders gut anwenden und bewerten lassen \cite{tamanampudiAIEnhancedContinuousIntegration}.

\subsection{Verwendete Algorithmen}
\label{subsec:methodenAlgorithmen}
Die in den Publikationen verwendeten Algorithmen lassen sich den jeweiligen Lernparadigmen zuordnen. 
Die Analyse zeigt, dass im Kontext des Platform Engineerings eine Vielfalt an KI- und Verfahren des maschinellen Lernens (ML) eingesetzt wird.
Für eine systematische Bewertung wurde eine eigene Kategorisierung entwickelt.
Den Ausgangspunkt bildet die Tabelle aus \textcite{enemosahEnhancingDevOpsEfficiency2025}, in der verschiedene KI-Techniken für Testfallpriorisierung beschrieben werden. 
Die Einteilung wurde für den breiteren Kontext dieser Arbeit angepasst.

Auf dieser Basis wurden vier Kategorien definiert, die in Kapitel \ref{tab:tabelleMethodenAlgorithmen} kurz beschrieben sind. 
Anschließend folgt die quantitative Auswertung der identifizierten Methoden und Algorithmen. 
Dies zeigt, wie häufig die jeweiligen Verfahren in den Publikationen genannt werden. 

Die Ergebnisse zeigen ein deutliches Übergewicht von Deep Learning / neuronalen Netzen, die in 89\% (16/18) der Publikationen eingesetzt oder thematisiert werden. 
Klassische Klassifikation/Regression tritt mit 44\% (8/18) ebenfalls häufig auf. 
Ensemble- und baumbasierte Verfahren werden in 39\% (7/18) der Arbeiten genannt. 
Clustering ist mit 33\% (6/18) vertreten. Insgesamt zeigt sich, dass insbesondere neuronale Netze die dominierende Methodenklasse bilden.
In der Literatur dominieren Deep-Learning-Verfahren, insbesondere aufgrund ihrer Eignung zur Verarbeitung heterogener Daten wie Logs, Metriken und Text.
Gleichzeitig zeigen die Arbeiten, dass für einzelne Aufgaben auch einfachere Modelle ausreichend sind, diese jedoch seltener im Fokus der Forschung stehen \cite{enemosahEnhancingDevOpsEfficiency2025,tamanampudiAIEnhancedContinuousIntegration}.

Diese Verteilung ist in der Abbildung \ref{fig:04_01_04_algorithmen} dargestellt.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_01_quantitativ/04_01_04_algorithmen.png}
    \caption{Verteilung der Algorithmen und angesprochenen Methoden}
    \label{fig:04_01_04_algorithmen}
\end{figure}
