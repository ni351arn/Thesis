\section{Konzeptionelle Zuordnung}
\label{sec:matching-framework}

Aufbauend auf den quantitativen Ergebnissen aus Abschnitt 4.1 sowie den Mustern der Mapping-Studie in Abschnitt 4.2 wird in diesem Abschnitt eine konzeptionelle Zuordnung abgeleitet.
Ziel ist es, die identifizierten \gls{ki}-Ansätze zu übertragbaren Anwendungsmustern für generische Use Cases zu überführen.

\subsection{Intelligente Betriebsautomatisierung}
\label{subsec:intelligente-betriebsautomatisierung}
Das Muster Intelligente Betriebsautomatisierung beschreibt den Einsatz von \gls{ki} im laufenden Plattformbetrieb.
Der Schwerpunkt liegt auf der Bewertung von Systemzuständen und der Ableitung von Handlungsempfehlungen, um Stabilität und Verfügbarkeit der Plattform sicherzustellen.
Tabelle \ref{tab:betriebOrchestrierung} ordnet das Muster als konkrete Plattformaufgabe im Plattformbetrieb ein und fasst zentrale Ausprägungen zusammen.

\input{tables/04_ergebnisse/04_03_01_matchingTabelleEins.tex}

Verarbeitet werden Metriken, Protokolle und Zustandsinformationen aus dem Cluster (z. B. \gls{cpu}-Auslastung), die aus dem laufenden Betrieb anfallen.
Anhand historischer Verläufe werden typische Lastmuster und Abweichungen vom Normalbetrieb erkannt.
Darauf aufbauend werden operative Maßnahmen abgeleitet und als Handlungsempfehlungen bereitgestellt.
Prädiktives Auto-Scaling stellt einen Teilaspekt des Musters dar.
Dabei werden historische Last- und Auslastungsverläufe genutzt, um zukünftige Ressourcenbedarfe vorab abzuschätzen und Skalierungsentscheidungen zeitlich vorzuziehen.
Im Vergleich zu schwellwertbasierter Skalierung können Lastspitzen dadurch abgefedert werden, bevor es zu Überlastungen oder instabilen Laufzeiteigenschaften kommt.
Der Fokus liegt auf der Koordination betrieblicher Informationen, bei der Lastverteilung und bekannte Fehlerbilder im Kontext des laufenden Betriebs eingeordnet werden \cite{zaaloukCLOUDNATIVEARTIFICIAL,jossonpaulkalapparambathAdvancingDistributedSystems2025}.
Der Nutzen zeigt sich in einer Reduktion manueller Analysearbeit sowie in stabileren Laufzeiteigenschaften der Plattform.
Die Qualität der Entscheidungen hängt dabei von der Verlässlichkeit der zugrunde liegenden Betriebsdaten ab \cite{tamminediAutomatingKubernetesOperations2024,reddygopireddyIntegratingAIDevOps2022}.
Die Umsetzung erfordert eine durchgängige Erfassung von Betriebsdaten sowie definierte Schnittstellen für operative Maßnahmen.
Zusätzlich entstehen Herausforderungen durch die eingeschränkte Nachvollziehbarkeit lernbasierter Entscheidungen und den erhöhten Integrationsaufwand \cite{supritpattanayakIntegratingAIDevOps2024,uddohAIBasedThreatDetection2021}.

\subsection{Automatisierte Release-Absicherung}
\label{subsec:automatisierte-release-absicherung}

Das Muster Automatisierte Release-Absicherung adressiert die Absicherung von Rollouts, indem fehlerhafte Versionen möglichst früh erkannt und automatisiert begrenzt werden.
Die Tabelle \ref{tab:automatisierteReleaseAbsicherung} fasst dieses Muster als Plattformaufgabe zusammen.
Laufzeitdaten wie Latenz und Fehlerraten werden während des Rollouts kontinuierlich ausgewertet, und bei auffälligen Abweichungen wird automatisch gestoppt oder auf eine stabile Vorgängerversion zurückgesetzt.

\input{tables/04_ergebnisse/04_03_02_matchingTabelleZwei.tex}

Verfahren zur Erkennung von Abweichungen vom normalen Systemverhalten kommen zum Einsatz, um problematische Änderungen frühzeitig zu identifizieren \cite{tamanampudiAIEnhancedContinuousIntegration}.
Als operativer Mehrwert wird in den betrachteten Studien eine verkürzte Wiederherstellungszeit sowie eine höhere Systemverfügbarkeit beschrieben, da fehlerhafte Versionen schneller erkannt und automatisiert zurückgenommen werden können \cite{kankanalaAIMLDevOps2024,jossonpaulkalapparambathAdvancingDistributedSystems2025,tamanampudiAIEnhancedContinuousIntegration}.
In der Praxis zeigen sich jedoch Grenzen durch Fehlalarme, die unnötige Rücksetzungen auslösen können, sowie durch zusätzlichen Validierungs- und Abstimmungsaufwand.
Für eine robuste Umsetzung sind eine stabile Referenz für das Normalverhalten sowie automatisierte Abbruch- und Wiederherstellungsmechanismen und eine kontinuierliche Erfassung relevanter Rollout-Metriken erforderlich.

\subsection{Intelligente Build-Fehlerdiagnose}
\label{subsec:intelligente-build-fehlerdiagnose}

Das Muster Intelligente Build-Fehlerdiagnose adressiert die Frage, wie Fehlschläge in CI-Pipelines frühzeitig erkannt und die Ursachenanalyse im Entwicklungsprozess unterstützt werden.
Tabelle \ref{tab:intelligenteBuildFehlerdiagnose} fasst dieses Muster als Plattformaufgabe zusammen, bei der Build- und Testprotokolle aus \gls{ci}-Pipelines automatisiert ausgewertet werden, um wiederkehrende Fehlermuster zu erkennen und einzugrenzen.
Durch die Auswertung historischer Build-Protokolle, Testergebnisse und Code-Merkmale werden Muster identifiziert, die auf bevorstehende Fehlschläge hinweisen, sodass Entwickler frühzeitig auf potenzielle Build-Probleme aufmerksam gemacht werden.

\input{tables/04_ergebnisse/04_03_03_matchingTabelleDrei.tex}

Hier werden vor allem \gls{sl}-Verfahren wie Random Forest und XGBoost eingesetzt. 
Sie werten frühere Build-Daten und Build-Logs aus und schätzen damit sowohl das Risiko eines Build-Fehlers als auch häufig die Art des Fehlers ab \cite{kankanalaAIMLDevOps2024,tamanampudiAIEnhancedContinuousIntegration,govindarajanMachineLearningBased2025}.
Ein zentrales Ziel ist dabei die Reduktion der mittleren Wiederherstellungsdauer (MTTR) nach fehlgeschlagenen Builds.
Der Nutzen im Betrieb liegt vor allem in schnelleren Rückmeldungen. 
Fehleranfällige Änderungen fallen früher auf, und die Fehlersuche wird erleichtert, da relevante Logstellen automatisch vorausgewählt werden. 
In den Studien zeigt sich dies unter anderem in kürzeren Bereitstellungszeiten und einer deutlich geringeren Zeit für die Fehlersuche \cite{kankanalaAIMLDevOps2024,tamanampudiAIEnhancedContinuousIntegration}.
Eine Herausforderung ist die ungleiche Verteilung der Daten. Build-Fehler treten deutlich seltener auf als erfolgreiche Builds, wodurch die Verfahren fehlerhafte Builds schlechter erkennen können.
Zusätzlich verändern sich typische Muster, wenn Pipeline-Schritte, Abhängigkeiten oder Build-Umgebungen angepasst werden. 
In solchen Fällen müssen die Verfahren regelmäßig überprüft und erneut angepasst werden.
Für einen stabilen Einsatz sind daher zentral gesammelte und einheitlich strukturierte Build- und Test-Logs notwendig. 
Zudem wird eine ausreichend große Historie benötigt, die Builds eindeutig mit Commit, Pipeline-Schritt und Artefaktversion verknüpft.

\subsection{Risikobasiertes Schwachstellen- und Compliance-Management}
\label{subsec:devsecops}

Das Muster Risikobasiertes Schwachstellen- und Compliance-Management wird in der Literatur häufig unter den Begriffen DevSecOps oder SecurityOps eingeordnet. 
Es beschreibt \gls{ki}-gestützte Ansätze, um Sicherheitsereignisse im Plattformbetrieb frühzeitig zu erkennen und Reaktionen gezielt zu priorisieren.
Tabelle \ref{tab:devsecops} fasst das Muster als Plattformaufgabe zusammen. 
\input{tables/04_ergebnisse/04_03_04_matchingTabelleVier.tex}

Im Fokus stehen dabei sowohl die Priorisierung von Sicherheits-Scans als auch die laufende Auswertung von Log- und Netzwerkdaten. 
Auf dieser Basis lassen sich sicherheitsrelevante Abweichungen früh erkennen und automatisierte Maßnahmen einleiten, etwa die gezielte Isolation betroffener Komponenten.
Als methodischer Ansatz werden in der Literatur sowohl \gls{dl}-Modelle (z. B. CNNs) als auch Gradient-Boosting-Verfahren (z. B. XGBoost) eingesetzt.
XGBoost kann dabei besonders dann stabil funktionieren, wenn es nur wenige echte Sicherheitsvorfälle in den Daten gibt \cite{uddohAIBasedThreatDetection2021,govindarajanMachineLearningBased2025}.
Der Nutzen im Betrieb liegt in einer besseren Erkennung bei weniger Fehlalarmen. 
Dadurch verringert sich der manuelle Aufwand, und kritische Funde können schneller weiterbearbeitet werden \cite{uddohAIBasedThreatDetection2021}.
Gleichzeitig kann der Betrieb aufwendig werden, weil \gls{dl}-Modelle beim Einsatz zusätzliche Rechenleistung benötigen und damit Kosten verursachen.
Zusätzlich steigen die Anforderungen an Datenschutz und Compliance, sobald Log- oder Netzwerkdaten personenbezogene Informationen enthalten und nach DSGVO verarbeitet werden müssen.
Für einen stabilen Einsatz ist daher eine verlässliche Erfassung von Netzwerk- und Logdaten erforderlich. 
Diese Daten müssen so zusammengeführt werden, dass sicherheitsrelevante Ereignisse nachvollziehbar eingeordnet und automatisierte Reaktionen gezielt und kontrolliert ausgelöst werden können.
