\section{Konzeptionelle Zuordnung}
\label{sec:matching-framework}

Aufbauend auf den quantitativen Ergebnissen aus Abschnitt 4.1 sowie den Mustern der Mapping-Studie in Abschnitt 4.2 wird in diesem Abschnitt eine konzeptionelle Zuordnung abgeleitet.
Ziel ist es, die identifizierten \gls{ki}-Ansätze zu übertragbaren Anwendungsmustern für generische Use Cases zu überführen.

\subsection{Proaktives Ressourcen-Management}
\label{subsec:proaktives-ressourcenmanagement}
Das Muster Proaktives Ressourcen-Management beschreibt \gls{ki}-gestützte Verfahren, um Infrastrukturressourcen vorausschauend und automatisiert an die erwartete Last anzupassen.
Tabelle \ref{tab:proaktivesRessourcenmanagement} fasst dieses Muster als konkrete Plattformaufgabe zusammen, bei der Instanzen oder Kubernetes-Pods (z.\,B. per Autoscaling/HPA) nicht nur reaktiv gesteuert werden.
Auf Basis historischer Betriebsdaten wie \gls{cpu}- und Speicherauslastung werden wiederkehrende Lastmuster erkannt und die Anzahl von Pods oder Instanzen frühzeitig angepasst, bevor Engpässe auftreten.

\input{tables/04_ergebnisse/04_03_01_matchingTabelleEins.tex}

In der Literatur werden dafür vor allem Verfahren zur Auswertung zeitlicher Verläufe sowie lernbasierte Ansätze zur Entscheidungsunterstützung beschrieben \cite{poudelAIDrivenIntelligentAutoScaling2025a}. 
Diese unterstützen die Ableitung von Skalierungsentscheidungen auf Basis historischer Auslastungsdaten.
Der Nutzen im Betrieb zeigt sich in einer gleichmäßigeren Ressourcennutzung und in geringeren Kosten, da Ressourcen bedarfsgerechter bereitgestellt werden \cite{karthikputhrayaRoleCloudNativeArchitectures2025}.
Die Umsetzung setzt jedoch voraus, dass ausreichend Verlaufsdaten aus dem Betrieb vorliegen und Eingriffe in die Skalierung automatisiert möglich sind. 
Zusätzlich steigt der Aufwand, wenn Modelle regelmäßig angepasst werden müssen oder Verzögerungen beim Start neuer Komponenten auftreten, etwa in serverlosen Umgebungen.

Es wird zwischen Betrieb auf eigener Infrastruktur (On-Premises) und Betrieb in externen Cloud-Umgebungen (Public Cloud) unterschieden.
Die praktische Relevanz des Musters hängt vom Betriebsmodell ab.
In der Public Cloud fängt automatische Skalierung viele Lastspitzen bereits ab, da zusätzliche Kapazität kurzfristig bereitgestellt werden kann.
Im On-Premises-Betrieb ist der Ansatz häufig relevanter.
Feste Kapazitätsgrenzen und längere Beschaffungszeiten lassen Fehlentscheidungen bei der Ressourcendimensionierung stärker wirken.


\subsection{Automatisierte Release-Absicherung}
\label{subsec:automatisierte-release-absicherung}

Das Muster Automatisierte Release-Absicherung adressiert die Absicherung von Rollouts, indem fehlerhafte Versionen möglichst früh erkannt und automatisiert begrenzt werden.
Die Tabelle \ref{tab:automatisierteReleaseAbsicherung} fasst dieses Muster als Plattformaufgabe zusammen.
Laufzeitdaten wie Latenz und Fehlerraten werden während des Rollouts kontinuierlich ausgewertet und bei auffälligen Abweichungen wird automatisch gestoppt oder auf eine stabile Vorgängerversion zurückgesetzt.

\input{tables/04_ergebnisse/04_03_02_matchingTabelleZwei.tex}

Verfahren zur Erkennung von Abweichungen vom normalen Systemverhalten kommen zum Einsatz, um problematische Änderungen frühzeitig zu identifizieren \cite{tamanampudiAIEnhancedContinuousIntegration}.
Als operativer Mehrwert wird in den betrachteten Studien eine verkürzte Wiederherstellungszeit sowie eine höhere Systemverfügbarkeit beschrieben, da fehlerhafte Versionen schneller erkannt und automatisiert zurückgenommen werden können \cite{kankanalaAIMLDevOps2024,jossonpaulkalapparambathAdvancingDistributedSystems2025,tamanampudiAIEnhancedContinuousIntegration}.
In der Praxis zeigen sich jedoch Grenzen durch Fehlalarme, die unnötige Rücksetzungen auslösen können, sowie durch zusätzlichen Validierungs- und Abstimmungsaufwand.
Für eine robuste Umsetzung sind eine stabile Referenz für das Normalverhalten sowie automatisierte Abbruch- und Wiederherstellungsmechanismen und eine kontinuierliche Erfassung relevanter Rollout-Metriken erforderlich.

\subsection{Intelligente Build-Fehlerdiagnose}
\label{subsec:intelligente-build-fehlerdiagnose}

Das Muster Intelligente Build-Fehlerdiagnose adressiert die Frage, wie Fehlschläge in CI-Pipelines frühzeitig erkannt und die Ursachenanalyse im Entwicklungsprozess unterstützt werden kann.
Tabelle \ref{tab:intelligenteBuildFehlerdiagnose} fasst dieses Muster als Plattformaufgabe zusammen, bei der Build- und Testprotokolle aus \gls{ci}-Pipelines automatisiert ausgewertet werden, um wiederkehrende Fehlermuster zu erkennen und einzugrenzen.
Durch die Auswertung historischer Build-Protokolle, Testergebnisse und Code-Merkmale werden Muster identifiziert, die auf bevorstehende Fehlschläge hinweisen, sodass Entwickler frühzeitig auf potenzielle Build-Probleme aufmerksam gemacht werden.

\input{tables/04_ergebnisse/04_03_03_matchingTabelleDrei.tex}

Hier werden vor allem SL-Verfahren wie Random Forest und XGBoost eingesetzt. 
Sie werten frühere Build-Daten und Build-Logs aus und schätzen damit sowohl das Risiko eines Build-Fehlers als auch häufig die Art des Fehlers ab \cite{kankanalaAIMLDevOps2024,tamanampudiAIEnhancedContinuousIntegration,govindarajanMachineLearningBased2025}.
Ein zentrales Ziel ist dabei die Reduktion der mittleren Wiederherstellungsdauer (MTTR) nach fehlgeschlagenen Builds.
Der Nutzen im Betrieb liegt vor allem in schnelleren Rückmeldungen. 
Fehleranfällige Änderungen fallen früher auf, und die Fehlersuche wird erleichtert, da relevante Logstellen automatisch vorausgewählt werden. 
In den Studien zeigt sich dies unter anderem in kürzeren Bereitstellungszeiten und einer deutlich geringeren Zeit für die Fehlersuche \cite{kankanalaAIMLDevOps2024,tamanampudiAIEnhancedContinuousIntegration}.
Eine Herausforderung ist die ungleiche Verteilung der Daten. Build-Fehler treten deutlich seltener auf als erfolgreiche Builds, wodurch die Verfahren fehlerhafte Builds schlechter erkennen können.
Zusätzlich verändern sich typische Muster, wenn Pipeline-Schritte, Abhängigkeiten oder Build-Umgebungen angepasst werden. 
In solchen Fällen müssen die Verfahren regelmäßig überprüft und erneut angepasst werden.
Für einen stabilen Einsatz sind daher zentral gesammelte und einheitlich strukturierte Build- und Test-Logs notwendig. 
Zudem wird eine ausreichende und große Historie benötigt, die Builds eindeutig mit Commit, Pipeline-Schritt und Artefaktversion verknüpft.

\subsection{Risikobasiertes Schwachstellen- und Compliance-Management}
\label{subsec:devsecops}

Das Muster Risikobasiertes Schwachstellen- und Compliance-Management wird in der Literatur häufig unter den Begriffen DevSecOps oder SecurityOps eingeordnet. 
Es beschreibt \gls{ki}-gestützte Ansätze, um Sicherheitsereignisse im Plattformbetrieb frühzeitig zu erkennen und Reaktionen gezielt zu priorisieren.
Tabelle \ref{tab:devsecops} fasst das Muster als Plattformaufgabe zusammen. 
Im Fokus stehen dabei sowohl die Priorisierung von Sicher- heits-Scans als auch die laufende Auswertung von Log- und Netzwerkdaten. 
Auf dieser Basis lassen sich sicherheitsrelevante Abweichungen früh erkennen und automatisierte Maßnahmen einleiten, etwa die gezielte Isolation betroffener Komponenten.

Als methodischer Ansatz werden in der Literatur sowohl \gls{dl}-Modelle (z. B. CNNs) als auch Gradient-Boosting-Verfahren (z. B. XGBoost) eingesetzt.
XGBoost kann dabei besonders dann stabil funktionieren, wenn es nur wenige echte Sicherheitsvorfälle in den Daten gibt \cite{uddohAIBasedThreatDetection2021,govindarajanMachineLearningBased2025}.
Der Nutzen im Betrieb liegt in einer besseren Erkennung bei weniger Fehlalarmen. 
Dadurch verringert sich der manuelle Aufwand, und kritische Funde können schneller weiterbearbeitet werden \cite{uddohAIBasedThreatDetection2021}.
Gleichzeitig kann der Betrieb aufwendig werden, weil \gls{dl}-Modelle beim Einsatz zusätzliche Rechenleistung benötigen und damit Kosten verursachen.
Zusätzlich steigen die Anforderungen an Datenschutz und Compliance, sobald Log- oder Netzwerkdaten personenbezogene Informationen enthalten und nach DSGVO verarbeitet werden müssen.
Für einen stabilen Einsatz ist daher eine verlässliche Erfassung von Netzwerk- und Logdaten erforderlich. 
Diese Daten müssen so zusammengeführt werden, dass sicherheitsrelevante Ereignisse nachvollziehbar eingeordnet und automatisierte Reaktionen gezielt und kontrolliert ausgelöst werden können.
\input{tables/04_ergebnisse/04_03_04_matchingTabelleVier.tex}
