\section{Matching-Framework}
\label{sec:matching-framework}

Aufbauend auf den quantitativen Ergebnissen aus Abschnitt 4.1 sowie den Mustern der Mapping Study in Abschnitt 4.2 wird in diesem Abschnitt ein konzeptionelles Matching-Framework abgeleitet.
Ziel ist es, die identifizierten KI-Ansätze in übertragbare Anwendungsmuster für generische Use Cases im Platform Engineering zu strukturieren und damit eine nachvollziehbare Grundlage zu schaffen, um KI-Lösungen später hinsichtlich operativem Nutzen und Umsetzbarkeit einzuordnen.

\subsection{Proaktives Ressourcen-Management}
\label{subsec:proaktives-ressourcenmanagement}
Das Muster Proaktives Ressourcen-Management beschreibt KI-gestützte Verfahren, um Infrastrukturressourcen vorausschauend und automatisiert an die erwartete Last anzupassen.
Tabelle \ref{tab:proaktivesRessourcenmanagement} fasst dieses Muster als konkrete Plattformaufgabe zusammen, bei der Instanztypen (EC2/RDS) oder Kubernetes-Pods (HPA) nicht reaktiv über statische Schwellwerte, sondern auf Basis prognostizierter CPU-/RAM-Spitzen gesteuert werden.

\input{tables/04_ergebnisse/04_03_01_matchingTabelleEins.tex}

Als methodischer Kern werden in der Literatur insbesondere Zeitreihenmodelle (z.B.\ LSTM) sowie Reinforcement-Learning-Ansätze beschrieben, die Skalierungs- und Allokationsentscheidungen dynamisch ableiten \cite{poudelAIDrivenIntelligentAutoScaling2025a}.
Der operative Nutzen zeigt sich in einer verbesserten Ressourcenauslastung gegenüber heuristischen Policies sowie in messbaren Kosteneffekten durch bedarfsgerechte Allokation \cite{karthikputhrayaRoleCloudNativeArchitectures2025}.
Gleichzeitig ist die praktische Umsetzbarkeit an Voraussetzungen wie ausreichend historischer Telemetrie und automatisierten Eingriffsmöglichkeiten (API-Schreibzugriffe) gebunden.
Zudem erhöhen Trainingsaufwand und Cold-Start-Effekte, insbesondere in serverlosen Umgebungen, die Implementierungs- und Betriebsanforderungen.


\subsection{Automatisierte Release-Absicherung}
\label{subsec:automatisierte-release-absicherung}

Das Muster Automatisierte Release-Absicherung adressiert die Absicherung von Deployments, indem fehlerhafte Releases möglichst früh erkannt und automatisiert begrenzt werden.
Tabelle \ref{tab:automatisierteReleaseAbsicherung} konkretisiert dieses Muster als Plattform-Task im Kontext von Canary-Deployments, bei denen neue Versionen schrittweise ausgerollt und anhand von Latenz- sowie Fehlerraten kontinuierlich überwacht werden.

\input{tables/04_ergebnisse/04_03_02_matchingTabelleZwei.tex}

Methodisch werden dafür insbesondere Anomalieerkennungsverfahren (z.B.\ Autoencoder) genutzt, um Abweichungen vom etablierten Normalverhalten zu detektieren, während Reinforcement Learning (z.B.\ DQN) eingesetzt werden kann, um den Rollback-Zeitpunkt unter Unsicherheit zu optimieren \cite{tamanampudiAIEnhancedContinuousIntegration}.
Als operativer Mehrwert wird in den betrachteten Studien eine Reduktion der Mean Time To Recovery (MTTR) sowie eine höhere Systemverfügbarkeit berichtet, da fehlerhafte Releases schneller identifiziert und automatisiert zurückgenommen werden können \cite{kankanalaAIMLDevOps2024,jossonpaulkalapparambathAdvancingDistributedSystems2025, tamanampudiAIEnhancedContinuousIntegration}.
Gleichzeitig zeigen sich in der Praxis Grenzen durch False Positives, die unnötige Rollbacks auslösen können, sowie durch zusätzlichen Validierungs- und Governance-Aufwand, insbesondere wenn RL-basierte Entscheidungen nachvollziehbar begründet werden müssen.
Für eine robuste Umsetzung sind daher eine belastbare Baseline für Normalverhalten aus service-mesh-gestützten Telemetriedaten (Traffic-Steuerung und Observability) sowie automatisierte Rollback-Mechanismen und ein Echtzeit-Streaming der relevanten Deployment-Metriken erforderlich.


\subsection{Intelligente Build-Fehlerdiagnose}
\label{subsec:intelligente-build-fehlerdiagnose}

Das Muster Intelligente Build-Fehlerdiagnose adressiert die Frage, wie CI-Pipelines Build-Fehlschläge frühzeitig erkennen und die Ursachenanalyse im Entwicklungsprozess beschleunigen können.
Tabelle \ref{tab:intelligenteBuildFehlerdiagnose} fasst das Muster als Plattformaufgabe zusammen, bei der Build- und Testprotokolle aus der CI (z.B.\ Jenkins und Git) automatisiert ausgewertet werden, um typische Fehlermuster zu identifizieren und wiederkehrende Fehlerbilder zu gruppieren.

\input{tables/04_ergebnisse/04_03_03_matchingTabelleDrei.tex}

Als methodische Grundlage dominieren SL Verfahren wie Random Forest und XGBoost, die aus historischen Build-Metadaten und Protokollmerkmalen sowohl das Risiko eines Fehlschlags als auch häufig den zu erwartenden Fehlertyp ableiten \cite{kankanalaAIMLDevOps2024,govindarajanMachineLearningBased2025,tamanampudiAIEnhancedContinuousIntegration}.
Der operative Mehrwert liegt in verkürzten Rückkopplungszyklen, da problematische Änderungen früher auffallen und die Fehlersuche durch eine automatisierte Vorselektion relevanter Protokollauszüge reduziert wird, was sich in den Studien u.a.\ in kürzeren Bereitstellungszeiten und einer deutlichen Reduktion der Fehlersuchzeit widerspiegelt \cite{kankanalaAIMLDevOps2024,tamanampudiAIEnhancedContinuousIntegration}.
Gleichzeitig ist die Umsetzung anfällig für unausgewogene Klassenverteilungen, da Fehlschläge in der Praxis typischerweise deutlich seltener als erfolgreiche Builds auftreten und Modelle dadurch verzerrt lernen können.
Zudem führen Änderungen an Pipeline-Schritten, Abhängigkeiten oder Build-Umgebungen häufig zu veränderten Datenmustern, wodurch ein kontinuierliches Überwachen und regelmäßiges Nachtrainieren erforderlich wird.
Voraussetzung für eine robuste Anwendung sind daher zentralisierte, konsistent strukturierte Protokolle sowie gelabelte Historien, die Builds zuverlässig mit Commit, Pipeline-Phase und Artefaktversion verknüpfen, sodass Fehlertypen eindeutig zugeordnet werden können.


\subsection{DevSecOps (Security Ops)}
\label{subsec:devsecops}

Das Muster DevSecOps (Security Ops) beschreibt KI-gestützte Mechanismen, um Sicherheitsereignisse im Plattformbetrieb frühzeitig zu erkennen und Reaktionsmaßnahmen zu priorisieren.
Tabelle \ref{tab:devsecops} fasst das Muster als Plattformaufgabe zusammen, bei der sowohl die Priorisierung von Sicherheits-Scans als auch die Echtzeit-Erkennung von Angriffen auf Basis von Netzwerk- und Audit-Telemetrie adressiert wird.

\input{tables/04_ergebnisse/04_03_04_matchingTabelleVier.tex}

Als methodische Grundlage werden in der Literatur sowohl Deep-Learning-Ans\"atze (z.B.\ CNNs) als auch Gradient-Boosting-Verfahren (z.B.\ XGBoost) diskutiert, wobei letzteres insbesondere bei unausgewogenen Sicherheitsdaten robuste Ergebnisse liefern kann \cite{govindarajanMachineLearningBased2025, uddohAIBasedThreatDetection2021}.
Der operative Mehrwert besteht in einer verbesserten Detektionsleistung bei gleichzeitiger Reduktion von Fehlalarmen, wodurch Security-Teams weniger Zeit in manuelle Triage investieren müssen und kritische Ereignisse schneller eskaliert werden können \cite{uddohAIBasedThreatDetection2021}.
Gleichzeitig ist die praktische Umsetzung an Grenzen gebunden, da Deep-Learning-Verfahren in der Inferenz einen erhöhten Rechenbedarf verursachen und damit zusätzliche Plattformkosten auslösen können.
Darüber hinaus entstehen Datenschutz- und Compliance-Anforderungen, sobald paketbasierte Protokolle oder Logdaten potenziell personenbezogene Informationen enthalten und entsprechend nach DSGVO verarbeitet werden müssen.
Für eine belastbare Anwendung sind daher eine Echtzeit-Erfassung von Netzwerk-Flows und relevanten Logdaten sowie eine Kontextualisierung über Threat-Intelligence-Informationen (z.B.\ MITRE ATT\&CK) erforderlich, um Funde priorisieren und automatisierte Reaktionen kontrolliert auslösen zu können.