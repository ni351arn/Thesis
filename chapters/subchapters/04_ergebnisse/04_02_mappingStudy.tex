\section{Ergebnisse der Mapping-Studie}
\label{sec:mapping-study-ergebnisse}

In diesem Abschnitt werden die Ergebnisse vertieft und mit einer Kreuztabellenanalyse präsentiert.
Diese Zuordnungen untersuchen Beziehungen zwischen Anwendungsfeldern und Herausforderungen (\ref{subsec:mappingEins}), Lernparadigmen und Algorithmen (\ref{subsec:mappingzwei}) sowie Anwendungsfelder und Datenquellen (\ref{subsec:mappingDrei}).
Die Ergebnisse werden als Bubble-Chart-Diagramme visualisiert, in denen die Blasengröße die Häufigkeit der jeweiligen Zuordnung ($n$) widerspiegelt.
Die Häufigkeiten ($n$) geben an, in wie vielen der betrachteten Studien die jeweilige Zuordnung vorkommt. 
Pro Studie wird eine Zuordnung je Kombination höchstens einmal gezählt, unabhängig davon, wie häufig sie im Text erwähnt wird.
Ziel ist es, durch diese systematischen Mappings tiefere Einblicke in Struktur und Schwerpunkte der aktuellen Forschung zu gewinnen.

\subsection{Zusammenspiel der Anwendungsfelder und Herausforderungen}
\label{subsec:mappingEins}
Die Abbildung \ref{fig:04_02_01_mapping} zeigt das Zusammenspiel zwischen den identifizierten Use Cases und den zentralen Herausforderungen im Platform Engineering. 
Im Gegensatz zur Abbildung \ref{fig:04_01_01_useCases} wurden hier alle in den analysierten Studien genannten Anwendungsbereiche berücksichtigt und den jeweils adressierten Herausforderungen zugeordnet. 
Die Häufigkeiten geben an, wie oft eine bestimmte Kombination in der Literatur thematisiert wurde.

Besonders deutlich wird die starke Verknüpfung der Use Cases Ressourcen- und Workload-Optimierung sowie Betrieb und Orchestrierung mit nahezu allen Herausforderungskategorien.
Die Ressourcen- und Workload-Optimierung weist über alle Bereiche hinweg hohe Werte auf ($n=15, 13, 12, 12, 11$). 
Diese breite Korrelation ist plausibel, da Ressourcen- und Workload-Optimierung einen besonders direkten Bezug zu Kosten hat und sich Effekte häufig über die Cloud-Abrechnung unmittelbar sichtbar machen.
\gls{ki}-gesteuertes Auto-Scaling vermeidet die Überbereitstellung von Ressourcen und senkt dadurch die monatlichen Abrechnungskosten direkt \cite{poudelAIDrivenIntelligentAutoScaling2025a}.
Echtzeit-Inferenz verkürzt die Reaktionszeit. Gleichzeitig steigt durch höheren Verbrauch von \gls{cpu} und Speicher der Ressourcen- und Kostenaufwand \cite{guptaCloudNativeMLArchitecting2024a}.

Ein sehr ähnliches Muster zeigt sich im Bereich Betrieb \& Orchestrierung, der ebenfalls in allen Herausforderungskategorien hohe Häufigkeiten erreicht ($n=15, 13, 13, 12, 11$). 
Das deutet darauf hin, dass \gls{ki} im Plattformbetrieb häufig nicht als Einzellösung betrachtet wird. 
Stattdessen ist sie meist in mehrere Betriebsbausteine eingebettet, z.B. Monitoring, Deployment, Orchestrierung und Governance.
Damit werden in diesem Bereich oft mehrere Herausforderungen gleichzeitig berührt, etwa Kosten, Skalierung, Integration und datenbezogene Voraussetzungen.

Der Use Case Sicherheits- und Bedrohungserkennung zeigt seine höchste Ausprägung im Bereich \gls{ki}-Governance, Datenschutz und Compliance ($n=14$) sowie bei Ressourcenverbrauch und Kosten ($n=13$). 
Auch die übrigen Herausforderungen weisen weiterhin hohe Werte auf ($n=11, 10, 10$). 
Dies deutet darauf hin, dass sicherheitsbezogene \gls{ki}-Ansätze neben Governance-Themen häufig auch Monitoring, Integrationsprozesse und die zugrunde liegende Datenlage betreffen.

Die Optimierung der \gls{ci}/\gls{cd}-Pipeline zeigt insgesamt die niedrigsten Werte, bleibt aber über alle Herausforderungen hinweg relativ konstant ($n=9, 7, 9, 8, 8$). 
\gls{ki} wird hier vor allem eingesetzt, um einzelne Schritte wie Builds, Tests oder Deployments zu verbessern. 
Im Vergleich zu ressourcen- oder betriebsnahen Use Cases werden jedoch weniger Herausforderungen gleichzeitig berührt. 
Kosten, Tool-Abhängigkeiten und Governance-Fragen bleiben trotzdem relevant, etwa durch zusätzlichen Rechenaufwand und die notwendige Nachvollziehbarkeit automatisierter Entscheidungen \cite{tamanampudiAIEnhancedContinuousIntegration}.

Insgesamt verdeutlicht die Verteilung der Häufigkeiten, dass \gls{ki}-Anwendungen im Platform Engineering besonders dort adressiert werden, wo betriebliche Effizienz und Automatisierung direkt mit Kosten, Skalierung, Governance
und Integrationsfragen zusammenwirken. 
Die Häufungen zeigen somit, welche Themen in der Forschung besonders im Fokus stehen und in welchen Bereichen \gls{ki}-Lösungen aktuell besonders häufig diskutiert werden.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_02_mapping/04_02_01_mapping.png}
    \caption{Korrelation zwischen Anwendungsfeldern und Herausforderungen}
    \label{fig:04_02_01_mapping}
\end{figure}
\FloatBarrier

\subsection{Zusammenspiel der Lernparadigmen und Algorithmen}
\label{subsec:mappingzwei}
Die Abbildung \ref{fig:04_02_02_mappingZwei} visualisiert die Korrelation zwischen den in den analysierten Studien verwendeten Lernparadigmen des maschinellen Lernens und den eingesetzten Algorithmen.
Einige Kombinationen werden in der Darstellung nicht ausgewiesen ($n=0$ bzw. ohne Blase), da sie in den betrachteten Studien nicht eindeutig als eigenständige Zuordnung berichtet wurden.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_02_mapping/04_02_02_mappingZwei.png}
    \caption{Korrelation zwischen Lernparadigmen und Algorithmen}
    \label{fig:04_02_02_mappingZwei}
\end{figure}

\gls{sl} weist im Mapping die größte Bandbreite auf.
Es wird am häufigsten mit \gls{dl} / \gls{nn} kombiniert ($n=14$), gefolgt von Klassifikation / Regression ($n=8$) sowie Ensemble- und baum-basierten Verfahren ($n=7$).
Damit dominiert \gls{sl} sowohl in der Anzahl der Nennungen als auch in der Vielfalt der berichteten Verfahren.
Mehrere Arbeiten beschreiben \gls{sl} als zentralen Ansatz zur Optimierung einzelner Pipeline-Schritte, etwa für Test-, Build- oder Deploy-Entscheidungen \cite{enemosahEnhancingDevOpsEfficiency2025,tamanampudiAIEnhancedContinuousIntegration}.

\gls{ul} zeigt hingegen ein engeres Spektrum.
Im Mapping dominieren \gls{dl}-basierte Ansätze ($n=9$) sowie Clustering ($n=6$).
Der Schwerpunkt liegt dabei auf der Muster- und Anomalieerkennung.
Mehrere Arbeiten zeigen, dass sich das erlernte Normalverhalten in dynamischen Plattformumgebungen häufig verändert und ohne Anpassung der Modelle vermehrt Fehlalarme entstehen \cite{enemosahEnhancingDevOpsEfficiency2025,tamanampudiAIEnhancedContinuousIntegration}.

\gls{rl} tritt in mehreren Studien auf, wird jedoch selten algorithmisch konkretisiert.
Berichtet werden ausschließlich Kombinationen mit \gls{dl} / \gls{nn} ($n=7$).
Zwar werden in einzelnen Arbeiten konkrete \gls{rl}-Algorithmen genannt, zugleich beschreiben die Studien jedoch einen hohen Rechen- und Zeitaufwand sowie eine komplexe Implementierung als zentrale Herausforderungen \cite{enemosahEnhancingDevOpsEfficiency2025,jossonpaulkalapparambathAdvancingDistributedSystems2025}.
Insgesamt bleibt die Zuordnung zu spezifischen Algorithmen begrenzt, weshalb viele Kombinationen in der Tabelle nicht belegt sind.
\FloatBarrier


\subsection{Zusammenspiel der Anwendungsfelder und Datenquellen}
\label{subsec:mappingDrei}
In diesem Unterkapitel wird analysiert, welche Datenquellen in den identifizierten Anwendungsfeldern genutzt werden.
Dafür wurden alle angesprochenen Anwendungsfelder pro Studie mit den jeweils verwendeten Datenquellen verknüpft.
Abbildung \ref{fig:04_02_03_mappingDrei} zeigt die resultierenden Häufigkeiten (n) je Kombination.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/04_ergebnisse/04_02_mapping/04_02_03_mappingDrei.png}
    \caption{Korrelation zwischen Anwendungsfeldern und Datenquellen}
    \label{fig:04_02_03_mappingDrei}
\end{figure}

Metriken beschreiben den quantitativen Systemzustand, etwa \gls{cpu}, Speicher oder Latenzen.
Sie stammen häufig aus Monitoring-Systemen wie Prometheus\footnote{\url{https://prometheus.io/docs/introduction/overview/}} oder CloudWatch\footnote{\url{https://aws.amazon.com/de/cloudwatch/}}.
Entsprechend treten sie in nahezu allen Use Cases stark auf.
Besonders ausgeprägt sind sie in Betrieb / Orchestrierung ($n=14$) sowie in der Ressourcen- und Workload-Optimierung ($n=12$) \cite{kankanalaAIMLDevOps2024,poudelAIDrivenIntelligentAutoScaling2025a}.

Logs (System-, Pipeline- und Applikationslogs) sind ereignisbasierte, häufig unstrukturierte Daten und werden vor allem für Diagnose, Fehlerklassifikation und Ursachenanalyse genutzt.
Im Mapping zeigen sie über nahezu alle Use Cases hinweg eine zentrale Rolle ($n=6$ bis $10$), mit hohen Werten in Betrieb / Orchestrierung ($n=10$) und sicherheitsnahen Szenarien ($n=9$).
Betriebsstörungen, Fehlkonfigurationen oder sicherheitsrelevante Ereignisse lassen sich in Logdaten erkennen \cite{kathiresanCybersecurityRiskModeling2025}.

Netzwerkdaten und Traces ergänzen diese Sicht um Kommunikationsbeziehungen und Laufzeitpfade verteilter Systeme (z.\,B. Flow-Daten oder OpenTelemetry-Traces\footnote{\url{https://opentelemetry.io}}).
Die Ausprägung ist insgesamt niedriger als bei Metriken und Logs, aber konsistent in Betrieb / Orchestrierung ($n=6$) sowie Sicherheits- und Bedrohungserkennung ($n=5$) vorhanden. 
Das deutet darauf hin, dass diese Daten vor allem dann relevant werden, wenn Ursachen nicht lokal erklärbar sind (z.\,B. in Mikroservice-Architekturen) oder wenn Anomalien über Kommunikationsmuster erkannt werden sollen \cite{zaaloukCLOUDNATIVEARTIFICIAL}.

Code und Konfiguration (Quellcode, Container-Artefakte, Infrastructure-as-Code-Definitionen) werden wichtig, wenn \gls{ki} nicht nur Symptome bewertet, sondern Änderungen und Konfigurationsstände einbezieht.
Im Mapping zeigt sich eine breite Nutzung über alle Use Cases ($n=7$ bis $9$).
Auffällig ist die hohe Ausprägung bei Betrieb / Orchestrierung und Sicherheit (je $n=9$), was zu riskanten Änderungen, unsicheren Voreinstellungen oder Fehlkonfigurationen passt \cite{supritpattanayakIntegratingAIDevOps2024}.

Historische Test- und Deployment-Daten (Build-Historien, Testergebnisse, Deployment-Verläufe) treten vor allem dort auf, wo Verfahren aus vergangenen Ausführungen lernen.
Im Mapping zeigen sich erhöhte Werte bei Betrieb / Orchestrierung ($n=12$), Ressourcenoptimierung ($n=10$) und \gls{ci}/\gls{cd}-Optimierung ($n=9$) \cite{tamanampudiAIEnhancedContinuousIntegration}.

Deutlich wird, dass Betrieb / Orchestrierung die stärksten Überschneidungen mit nahezu allen Datenquellen aufweist, weil hier Monitoring-Daten und Änderungsdaten zusammenlaufen.
Ohne dieses Gesamtbild gelingt eine saubere Steuerung \gls{ki}-gestützter Abläufe nur eingeschränkt.
Das erhöht die Wahrscheinlichkeit von Fehlalarmen und erschwert die Eingrenzung der eigentlichen Ursache.
\FloatBarrier

