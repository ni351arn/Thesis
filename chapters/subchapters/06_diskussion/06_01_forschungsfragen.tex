\section{Beantwortung der Forschungsfragen}
\label{sec:beantwortung-ff}
In diesem Abschnitt werden die drei Forschungsfragen der Arbeit (RQ1, RQ2, RQ3) auf Basis der erarbeiteten Ergebnisse beantwortet.
Die Antworten beziehen sich auf die in der Literaturanalyse identifizierten Anwendungsfelder und Herausforderungen (RQ1), die untersuchten \gls{ki}-Methoden und -Werkzeuge (RQ2) sowie das entwickelte Bewertungskonzept und dessen Anwendung auf einen konkreten Anwendungsfall (RQ3).
Damit werden die in \autoref{sec:forschungsfragen} formulierten Fragen beantwortet und die Erkenntnisse in den Gesamtkontext des Cloud-Native Platform Engineerings eingeordnet.

\subsection{Beantwortung der Forschungsfrage RQ1}
\label{rq1Antwort}
Die Literaturanalyse zeigt vier wiederkehrende Anwendungsfelder, in denen \gls{ki} einen Mehrwert bringt und gleichzeitig Herausforderungen auftreten.
Diese lassen sich entlang konkreter betrieblicher Aufgaben abgrenzen: (1) Ressourcen- und Workload-Optimierung, (2) Betrieb und Orchestrierung der Plattform, (3) Optimierung von \gls{ci}/\gls{cd}-Pipelines sowie (4) Sicherheits- und Bedrohungserkennung. 

Das Proaktive Ressourcen-Management thematisiert die Skalierung von Workloads, zum Beispiel die Anpassung der Anzahl von Kubernetes-Pods bei schwankender Last.
Die \gls{ki} wertet Auslastungs- und Latenzverläufe aus und leitet daraus eine Vorhersage für die nächste Lastphase ab.
Auf Basis dieser Vorhersage wird eine Skalierungsentscheidung früher getroffen als bei fester Zuteilung.
Dadurch sinkt das Risiko, dass Services zu spät skalieren und unter Last instabil werden.
Gleichzeitig wird eine Überbereitstellung reduziert, weil nicht zu viel Kapazität vorgehalten wird.
Typische Herausforderungen entstehen, wenn nicht ausreichend historische Daten vorliegen oder Lastmuster sich häufig ändern \cite{tamminediAutomatingKubernetesOperations2024,poudelAIDrivenIntelligentAutoScaling2025a}.

Betrieb und Orchestrierung adressiert Störungen im laufenden Betrieb und die Eingrenzung ihrer Ursachen über mehrere Komponenten hinweg.
Die Grundlage bilden Protokolle, Metriken und Ereignisse, die Hinweise geben, welche Komponente wahrscheinlich der Auslöser ist.
Ein typisches Beispiel ist die Auswertung von Kubernetes-Events und Protokollen, um Fehlkonfigurationen oder wiederkehrende Fehlerbilder schneller zu erkennen.
Der Mehrwert liegt in kürzerer Fehlersuche und einer schnelleren Einordnung, was relevant ist.
Der Ansatz wird unzuverlässig, wenn sich das Normalverhalten durch Releases und Konfigurationsänderungen ständig verschiebt und dadurch viele Fehlalarme entstehen \cite{tamminediAutomatingKubernetesOperations2024,tamanampudiAIEnhancedContinuousIntegration}.

Die Absicherung von Rollouts zielt darauf ab, fehlerhafte Versionen früh zu begrenzen.
Während einer schrittweisen Rollout-Phase werden Fehlerraten und Antwortzeiten beobachtet und mit dem erwarteten Normalzustand verglichen.
Bei auffälligen Abweichungen kann ein Rollout gestoppt oder auf die letzte stabile Version zurückgesetzt werden.
Das ist relevant, weil Rollouts regelmäßig sind und Fehler sonst erst sichtbar werden, wenn sie bereits breiter wirken.
Problematisch wird es, wenn normale Schwankungen nicht sauber von echten Fehlern getrennt werden und dadurch unnötige Rücksetzungen ausgelöst werden \cite{tamanampudiAIEnhancedContinuousIntegration}.

Sicherheits- und Bedrohungserkennung umfasst die Anomalieerkennung, Echtzeiterkennung von Angriffen sowie die Klassifikation von Bedrohungen.
Ein konkretes Beispiel ist der Einsatz von SL-Algorithmen, um erkannte Anomalien als bösartig oder gutartig einzustufen. 
Ergänzend können Laufzeitdaten Hinweise liefern, ob ein Fund in der konkreten Nutzung überhaupt wirksam wird.
Dadurch fließt weniger Zeit in unkritische Funde und relevante Punkte können schneller bearbeitet werden.
Grenzen entstehen durch sensible Daten und Vorgaben, weil Protokolle und Sicherheitsdaten nicht beliebig ausgewertet und aufbewahrt werden dürfen \cite{kankanalaAIMLDevOps2024,uddohAIBasedThreatDetection2021}.

Über alle Felder zeigen sich wiederkehrende Herausforderungen.
Dazu zählen zusätzlicher Rechen- und Betriebsaufwand, Integrationsaufwand sowie Einschränkungen durch Datenschutz und Freigaben.
Am häufigsten limitiert jedoch die Datenbasis, weil unvollständige oder uneinheitliche Daten zu instabilen Ergebnissen führen.

\subsection{Beantwortung der Forschungsfrage RQ2}
\label{rq2Antwort}
Die Literatur zeigt kein einheitliches Lernparadigma, Werkzeug oder Algorithmus, der für alle Anwendungsfälle gleichermaßen geeignet ist.
Die Wahl hängt vom Anwendungsfall, von der verfügbaren Datenbasis und von der Systemarchitektur der Plattform ab.

Am häufigsten werden \gls{sl}-Verfahren thematisiert und eingesetzt.
Sie eignen sich, wo historische Daten mit bekannten Ergebnissen vorliegen, zum Beispiel erfolgreiche und fehlgeschlagene Builds oder klassifizierte Störungen.
Damit lassen sich Vorhersagen für Lastverläufe erstellen oder Fehlertypen aus Protokollen einordnen.
Auch die Bewertung von Änderungsrisiken in \gls{ci}/\gls{cd}-Pipelines wird so umgesetzt, indem frühere Pipeline-Verläufe als Trainingsgrundlage dienen \cite{enemosahEnhancingDevOpsEfficiency2025}.

\gls{ul}-Verfahren werden dort eingesetzt, wo solche Zuordnungen fehlen.
Typisch ist die Erkennung von Abweichungen in Metriken oder Protokollen, ohne dass vorher markiert wurde, was ein Fehler ist.
Das ist im Betrieb hilfreich, erfordert aber saubere Referenzwerte und robuste Schwellen. 
Ohne diese sinkt die Trefferqualität und es entstehen mehr Fehlalarme \cite{tamanampudiAIEnhancedContinuousIntegration}.

Etwas weniger thematisiert aber trotzdem relevant sind \gls{rl}-Ansätze.
Diese werden vor allem für Steuerungsentscheidungen beschrieben, zum Beispiel für Skalierung oder Rollout-Entscheidungen unter wechselnden Bedingungen.
Der Aufwand ist hoch, weil Training und Rückkopplung sauber abgebildet werden müssen.
Daher ist der Einsatz in produktiven Umgebungen bislang begrenzt \cite{jossonpaulkalapparambathAdvancingDistributedSystems2025,kathiresanCybersecurityRiskModeling2025}.

Bei den Methoden dominieren komplexe Modelle, besonders \gls{nn}.
Das liegt daran, dass sie mit heterogenen Betriebsdaten umgehen können, zum Beispiel mit Protokollen, Metriken und Ereignissen \cite{enemosahEnhancingDevOpsEfficiency2025}.
Daneben werden auch klassische Verfahren genutzt, etwa baumbasierte Modelle für Klassifikation und Prognosen, oder Clustering für die Gruppierung ähnlicher Fehlerbilder.
In mehreren Arbeiten wird deutlich, dass einfachere und besser nachvollziehbare Verfahren in manchen Fällen ausreichen würden, in der Forschung aber seltener im Fokus stehen \cite{govindarajanMachineLearningBased2025}.

Bei den Werkzeugen zeigt sich, dass viele Ansätze auf bestehenden Plattform- und Betriebswerkzeugen aufbauen und diese um \gls{ki}-Funktionen ergänzen.
Im Kubernetes-Umfeld betrifft das zum Beispiel Autoscaling und die Auswertung von Events und Protokollen.
Im \gls{ci}/\gls{cd}-Kontext werden Werkzeuge wie K8sGPT \cite{zaaloukCLOUDNATIVEARTIFICIAL}, Jenkins X \cite{kankanalaAIMLDevOps2024} oder DeepCode \cite{supritpattanayakIntegratingAIDevOps2024} genannt, um Build- und Analyseaufgaben zu unterstützen.
Für Rollout-Absicherung und Betrieb werden auch Plattformen wie Spinnaker oder Dynatrace \cite{supritpattanayakIntegratingAIDevOps2024} beschrieben, die Daten aus dem Betrieb auswerten und Hinweise ableiten.
Im Sicherheitskontext werden Werkzeuge wie Trivy \cite{kankanalaAIMLDevOps2024}, Snyk \cite{sikhaCloudNativeApplicationDevelopment2023} oder Falco \cite{sikhaCloudNativeApplicationDevelopment2023} genannt, die Funde aus Scans und Laufzeitdaten priorisieren.


\subsection{Beantwortung der Forschungsfrage RQ3}
\label{rq3Antwort}
Eine qualitative Bewertung und Priorisierung von \gls{ki}-Use-Cases ist möglich, wenn \gls{ki}-Ansätze nicht isoliert betrachtet werden, sondern systematisch in den betrieblichen Kontext eingeordnet werden.
Als Ausgangspunkt dient die Einordnung nach Implementierungsaufwand und operativem Mehrwert \cite{tamminediAutomatingKubernetesOperations2024}.
Damit lässt sich jedoch nur grob abschätzen, ob ein Anwendungsfall grundsätzlich sinnvoll erscheint. Für eine belastbare Aussage zur praktischen Umsetzbarkeit und zur erwarteten Wirkung sind ergänzende Dimensionen erforderlich.

Die Umsetzbarkeit lässt sich anhand der verfügbaren Datenqualität und -historie, des technischen Fits zur bestehenden Plattformarchitektur sowie des erforderlichen Fachwissens für Betrieb und Wartung bewerten \cite{enemosahEnhancingDevOpsEfficiency2025,reddygopireddyIntegratingAIDevOps2022}.
Die betriebliche Wirksamkeit ergibt sich daraus, dass der Use Case im laufenden Betrieb stabil einen messbaren Nutzen entfaltet und mit vertretbarem Aufwand auf weitere Services übertragbar ist \cite{kankanalaAIMLDevOps2024,tamminediAutomatingKubernetesOperations2024}.
Ergänzend beeinflussen Anforderungen aus Datenschutz und Governance sowie der Reifegrad der jeweiligen Lösung, ob ein Einsatz realistisch und dauerhaft tragfähig ist \cite{supritpattanayakIntegratingAIDevOps2024,uddohAIBasedThreatDetection2021}.

Die qualitative Bewertung entlang einheitlicher Kriterien ermöglicht es, \gls{ki}-Use-Cases systematisch einzuordnen und miteinander zu vergleichen.
Dabei ist nicht entscheidend, welche konkrete \gls{ki}-Methode oder welches Werkzeug eingesetzt wird.
Maßgeblich ist vielmehr, in welchem Verhältnis Implementierungsaufwand, erwarteter Nutzen und betriebliche Rahmenbedingungen zueinander stehen.
Die Übertragbarkeit von \gls{ki}-Lösungen ergibt sich damit nicht aus der Technologie selbst, sondern aus ihrer Passung zur Datenbasis, zu bestehenden Betriebsprozessen und zur organisatorischen Struktur der Plattform.

Die Anwendung des Bewertungskonzepts auf die \gls{bmlp} zeigt, dass sich generische Use-Case-Muster aus der Literatur auf einen konkreten Plattformkontext übertragen lassen.
Use Cases mit vorhandener Datenbasis und klarer Anbindung an bestehende Prozesse lassen sich nachvollziehbar bewerten und priorisieren.
Gleichzeitig werden Anwendungsfälle sichtbar, deren Umsetzung zwar theoretisch möglich ist, bei denen jedoch Aufwand oder betriebliche Risiken aktuell überwiegen.
Damit wird eine fundierte Entscheidungsgrundlage geschaffen, die über eine rein werkzeug- oder technologiegetriebene Betrachtung hinausgeht.

RQ3 wird damit beantwortet, indem ein nachvollziehbarer Zusammenhang zwischen \gls{ki}-Ansätzen, konkreten Plattform-Use-Cases und deren Umsetzbarkeit hergestellt wird.